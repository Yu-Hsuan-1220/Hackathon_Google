import React, { useState, useEffect, useRef, useCallback } from 'react';
import PhoneContainer from './PhoneContainer';
import './SingleNoteLessonPage.css';

// éŒ„éŸ³ç§’æ•¸å¸¸æ•¸
const RECORD_SECONDS = 4;

// ç‹€æ…‹ç®¡ç†çš„åˆå§‹ç‹€æ…‹
const initialState = {
  phase: 'intro', // intro â†’ idle â†’ recording â†’ uploading â†’ playing â†’ done
  currentNote: '', // ç•¶å‰è¦æ¸¬è©¦çš„éŸ³ç¬¦
  answeredNotes: new Set(), // å·²ä½œç­”çš„éŸ³ç¬¦é›†åˆ
  questionResults: new Map(), // æ¯é¡Œçš„çµæœ Map<note, {success: boolean, attempts: number}>
  error: null,
  recordingTime: 0,
  audioLevel: 0,
  isPlayingInstruction: false
};

const SingleNoteLessonPage = ({ onNavigate, navigationSource }) => {
  const [state, setState] = useState(initialState);
  const [userName] = useState(localStorage.getItem('userName') || 'ç”¨æˆ¶');
  const [stream, setStream] = useState(null);
  const streamRef = useRef(null);  // æ–°å¢ streamRef
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const recordingTimerRef = useRef(null);
  const audioLevelTimerRef = useRef(null);  // æ–°å¢
  const analyserRef = useRef(null);
  const animationFrameRef = useRef(null);
  const audioContextRef = useRef(null);
  const instructionAudioRef = useRef(new Audio());
  const hasInitialized = useRef(false); // é˜²æ­¢é‡è¤‡åˆå§‹åŒ–
  const startRecordingRef = useRef(null); // ä¿å­˜ startRecording å‡½æ•¸çš„å¼•ç”¨

  // æ’­æ”¾æŒ‡å°èªéŸ³
  const playInstructionAudio = useCallback(async (audioPath) => {
    return new Promise((resolve) => {
      setState(prev => ({ ...prev, phase: 'playing', isPlayingInstruction: true }));

      const audio = instructionAudioRef.current;

      // åœæ­¢ç¾æœ‰æ’­æ”¾ä¸¦é‡ç½®
      audio.pause();
      audio.currentTime = 0;

      // è™•ç†éŸ³æª”è·¯å¾‘ - ç¢ºä¿æ­£ç¢ºçš„å‰ç«¯è·¯å¾‘æ ¼å¼
      let finalAudioPath = audioPath;

      // å¦‚æœæ˜¯å¾Œç«¯è¿”å›çš„å®Œæ•´è·¯å¾‘ï¼Œéœ€è¦è½‰æ›
      if (audioPath && audioPath.startsWith('frontend/public/')) {
        finalAudioPath = audioPath.replace('frontend/public/', '/');
      } else if (audioPath && audioPath.startsWith('audio/')) {
        finalAudioPath = '/' + audioPath;
      } else if (audioPath && !audioPath.startsWith('/')) {
        finalAudioPath = '/' + audioPath;
      }

      console.log('ğŸµ åŸå§‹éŸ³æª”è·¯å¾‘:', audioPath);
      console.log('ğŸµ è™•ç†å¾Œè·¯å¾‘:', finalAudioPath);

      const handleEnded = () => {
        console.log('âœ… æŒ‡ç¤ºéŸ³æª”æ’­æ”¾å®Œæˆ');
        setState(prev => ({ ...prev, isPlayingInstruction: false, phase: 'idle' }));
        audio.removeEventListener('ended', handleEnded);
        audio.removeEventListener('error', handleError);
        audio.removeEventListener('canplaythrough', handleCanPlay);
        
        // æ’­æ”¾å®Œæˆå¾Œè‡ªå‹•é–‹å§‹éŒ„éŸ³ (å»¶é²500msé¿å…ç‹€æ…‹è¡çª)
        setTimeout(() => {
          console.log('ğŸ¤– è‡ªå‹•é–‹å§‹éŒ„éŸ³...');
          if (startRecordingRef.current) {
            startRecordingRef.current();
          }
        }, 500);
        
        resolve();
      };

      const handleError = (error) => {
        console.error('ğŸ”Š èªéŸ³æ’­æ”¾éŒ¯èª¤:', error);
        console.error('éŒ¯èª¤çš„éŸ³æª”è·¯å¾‘:', finalAudioPath);
        setState(prev => ({
          ...prev,
          isPlayingInstruction: false,
          phase: 'idle',  // Reset phase to idle on error too
          error: null // ä¸é¡¯ç¤ºéŸ³æª”æ’­æ”¾éŒ¯èª¤ï¼Œå› ç‚ºé€™ä¸æ˜¯é—œéµåŠŸèƒ½
        }));
        audio.removeEventListener('ended', handleEnded);
        audio.removeEventListener('error', handleError);
        audio.removeEventListener('canplaythrough', handleCanPlay);
        
        // æ’­æ”¾å¤±æ•—ä¹Ÿè‡ªå‹•é–‹å§‹éŒ„éŸ³ (å»¶é²500msé¿å…ç‹€æ…‹è¡çª)
        setTimeout(() => {
          console.log('ğŸ¤– æ’­æ”¾å¤±æ•—ï¼Œè‡ªå‹•é–‹å§‹éŒ„éŸ³...');
          if (startRecordingRef.current) {
            startRecordingRef.current();
          }
        }, 500);
        
        resolve();
      };

      const handleCanPlay = () => {
        console.log('ğŸµ éŸ³æª”å·²åŠ è¼‰ï¼Œé–‹å§‹æ’­æ”¾');
        audio.removeEventListener('canplaythrough', handleCanPlay);
        audio.play().catch(handleError);
      };

      audio.addEventListener('ended', handleEnded);
      audio.addEventListener('error', handleError);
      audio.addEventListener('canplaythrough', handleCanPlay);

      // è¨­ç½®éŸ³æº
      audio.src = finalAudioPath;
      audio.load(); // å¼·åˆ¶é‡æ–°åŠ è¼‰
    });
  }, []);

  // è™•ç†å¾Œç«¯å›æ‡‰
  const processLessonResponse = useCallback(async (response) => {
    try {
      console.log('ğŸ” Processing response:', response);

      // å¾å¾Œç«¯å›æ‡‰ä¸­æ­£ç¢ºæå–æ•¸æ“š
      const debugInfo = response.debug_info || {};
      const nextNote = debugInfo.target_note;
      const audioPath = debugInfo.audio_path;
      const tuningStatus = debugInfo.tuning_status;
      const isSuccess = debugInfo.success;

      console.log('ğŸ” Extracted nextNote:', nextNote);
      console.log('ğŸ” Extracted audioPath:', audioPath);
      console.log('ğŸ” Extracted tuningStatus:', tuningStatus);
      console.log('ğŸ” Extracted isSuccess:', isSuccess);
      console.log('ğŸ” Current state.currentNote:', state.currentNote);

      // Update state FIRST, before playing audio
      if (nextNote && nextNote !== '') {
        const isRetryingSameNote = nextNote === state.currentNote;
        console.log('ğŸ” Is retrying same note?', isRetryingSameNote);
        console.log('ğŸ” Updating currentNote from', state.currentNote, 'to', nextNote);
        setState(prev => {
          console.log('ğŸ” setState callback - prev.currentNote:', prev.currentNote, 'new currentNote:', nextNote);
          return {
            ...prev,
            currentNote: nextNote,
            phase: audioPath ? 'playing' : 'idle'  // Set to playing if we have audio to play
          };
        });
      }

      // Update results only for non-initialization requests
      if (state.currentNote && state.currentNote !== 'AA' && state.currentNote !== '') {
        console.log('ğŸ” Updating results for note:', state.currentNote);
        setState(prev => {
          const newResults = new Map(prev.questionResults);
          const currentResult = newResults.get(state.currentNote) || { success: false, attempts: 0 };
          newResults.set(state.currentNote, {
            success: isSuccess || currentResult.success,
            attempts: currentResult.attempts + 1
          });

          const newAnsweredNotes = new Set(prev.answeredNotes);
          if (isSuccess) {
            newAnsweredNotes.add(state.currentNote);
          }

          return {
            ...prev,
            questionResults: newResults,
            answeredNotes: newAnsweredNotes
          };
        });
      }

      // Play instruction audio AFTER state update
      if (audioPath) {
        console.log('ğŸ” Playing audio:', audioPath);
        await playInstructionAudio(audioPath);
      } else {
        console.log('ğŸ” No audio path, setting phase to idle');
        setState(prev => ({ ...prev, phase: 'idle' }));
      }

      // Check if lesson is complete (ç•¶ nextNote ç‚ºç©ºå­—ç¬¦ä¸²æ™‚è¡¨ç¤ºå®Œæˆ)
      if (nextNote === "") {
        console.log('ğŸ‰ Lesson complete!');
        setState(prev => ({ ...prev, phase: 'done' }));
        setTimeout(() => {
          onNavigate(navigationSource === 'picking-technique' ? 'picking-technique' : 'basic-lesson');
        }, 3000);
      }

    } catch (error) {
      console.error('è™•ç†å›æ‡‰å¤±æ•—:', error);
      setState(prev => ({
        ...prev,
        error: 'è™•ç†å›æ‡‰å¤±æ•—ï¼Œè«‹é‡è©¦',
        phase: 'idle'
      }));
    }
  }, [state.currentNote, onNavigate, playInstructionAudio]);

  // éŸ³é‡ç›£æ¸¬ - åƒè€ƒèª¿éŸ³å™¨ (ç§»åˆ°å‰é¢é¿å…åˆå§‹åŒ–éŒ¯èª¤)
  const startAudioLevelMonitoring = useCallback((stream) => {
    try {
      const audioContext = new AudioContext();
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(stream);

      analyser.fftSize = 256;
      microphone.connect(analyser);

      const dataArray = new Uint8Array(analyser.frequencyBinCount);

      audioLevelTimerRef.current = setInterval(() => {
        analyser.getByteFrequencyData(dataArray);
        const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
        setState(prev => ({ ...prev, audioLevel: average }));
      }, 100);

    } catch (error) {
      console.error('éŸ³é‡ç›£æ¸¬å¤±æ•—:', error);
    }
  }, []);

  // ç™¼é€è«‹æ±‚åˆ°å¾Œç«¯
  const sendLessonRequest = useCallback(async (targetNote, audioBlob) => {
    setState(prev => ({ ...prev, phase: 'uploading' }));

    try {
      const formData = new FormData();
      formData.append('target_note', targetNote);
      formData.append('username', userName); // æ–°å¢ç”¨æˆ¶å
      formData.append('file', audioBlob, `lesson-${targetNote}.webm`);

      console.log(`ğŸ“¡ ç™¼é€æ•™å­¸è«‹æ±‚ - éŸ³ç¬¦: ${targetNote}, ç”¨æˆ¶: ${userName}, éŸ³æª”å¤§å°: ${audioBlob.size} bytes`);
      console.log('ğŸ“‹ FormDataå…§å®¹:');
      for (let [key, value] of formData.entries()) {
        console.log(`  ${key}:`, value);
      }

      const response = await fetch('http://127.0.0.1:8000/simplenote/string_check', {
        method: 'POST',
        mode: 'cors',
        headers: { 'Accept': 'application/json' },
        body: formData
      });

      console.log(`ğŸ“¡ å›æ‡‰ç‹€æ…‹: ${response.status} ${response.statusText}`);

      if (!response.ok) {
        const errorText = await response.text();
        console.error('âŒ APIå›æ‡‰éŒ¯èª¤:', response.status, errorText);
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const result = await response.json();
      console.log('ğŸ“¦ æ”¶åˆ°å›æ‡‰:', result);

      await processLessonResponse(result);

    } catch (error) {
      console.error('ä¸Šå‚³å¤±æ•—:', error);
      setState(prev => ({
        ...prev,
        error: error.message.includes('fetch') ?
          'ç¶²è·¯é€£ç·šå¤±æ•—ï¼Œè«‹æª¢æŸ¥å¾Œç«¯æœå‹™æ˜¯å¦å•Ÿå‹•' :
          `è«‹æ±‚å¤±æ•—: ${error.message}`,
        phase: 'idle'
      }));
    }
  }, [processLessonResponse]);

  // ä¸Šå‚³éŒ„éŸ³ - ä½¿ç”¨ ref ä¾†é¿å…é–‰åŒ…é™·é˜±
  const currentNoteRef = useRef('');

  // åŒæ­¥ ref èˆ‡ state
  useEffect(() => {
    currentNoteRef.current = state.currentNote;
  }, [state.currentNote]);

  const uploadRecording = useCallback(async (audioBlob) => {
    try {
      console.log('ğŸ“¤ é–‹å§‹ä¸Šå‚³éŒ„éŸ³...');
      console.log('ğŸ” Current note for upload (from ref):', currentNoteRef.current);

      await sendLessonRequest(currentNoteRef.current, audioBlob);
    } catch (error) {
      console.error('ä¸Šå‚³éŒ„éŸ³å¤±æ•—:', error);
      setState(prev => ({
        ...prev,
        error: error.message,
        phase: 'idle'
      }));
    }
  }, [sendLessonRequest]);

  // é–‹å§‹éŒ„éŸ³ - å®Œå…¨åƒè€ƒèª¿éŸ³å™¨çš„å¯¦ç¾
  const startRecording = useCallback(async () => {
    try {
      setState(prev => ({ ...prev, error: null, recordingTime: 0, audioLevel: 0 }));

      console.log('ğŸ¤ è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™...');
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: 44100,           // æå‡æ¡æ¨£ç‡ä»¥æé«˜é »ç‡æª¢æ¸¬ç²¾åº¦
          echoCancellation: false,
          autoGainControl: false,
          noiseSuppression: false
        }
      });

      setStream(stream);
      streamRef.current = stream;  // ä¿å­˜åˆ° ref
      audioChunksRef.current = [];

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus',
        audioBitsPerSecond: 128000
      });

      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          console.log('ğŸ“¦ æ”¶åˆ°éŒ„éŸ³æ•¸æ“š:', event.data.size, 'bytes');
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        console.log('ğŸ¤ éŒ„éŸ³çµæŸ');
        const audioBlob = new Blob(audioChunksRef.current, {
          type: 'audio/webm;codecs=opus'
        });

        console.log('ğŸ“¦ éŸ³æª”å¤§å°:', audioBlob.size, 'bytes');
        uploadRecording(audioBlob);
      };

      setState(prev => ({ ...prev, phase: 'recording', recordingTime: 0 }));
      mediaRecorder.start();
      console.log(`ğŸ¤ é–‹å§‹éŒ„éŸ³ ${RECORD_SECONDS} ç§’...`);

      // éŒ„éŸ³è¨ˆæ™‚å™¨ - å®Œå…¨åƒè€ƒèª¿éŸ³å™¨
      let currentTime = 0;
      recordingTimerRef.current = setInterval(() => {
        currentTime += 0.1;
        setState(prev => ({ ...prev, recordingTime: currentTime }));
        if (currentTime >= RECORD_SECONDS) {
          // ç›´æ¥åœ¨é€™è£¡åœæ­¢éŒ„éŸ³ï¼Œé¿å…å¾ªç’°ä¾è³´
          if (recordingTimerRef.current) {
            clearInterval(recordingTimerRef.current);
            recordingTimerRef.current = null;
          }
          if (audioLevelTimerRef.current) {
            clearInterval(audioLevelTimerRef.current);
            audioLevelTimerRef.current = null;
          }
          if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
            mediaRecorderRef.current.stop();
          }
          if (streamRef.current) {
            streamRef.current.getTracks().forEach(track => track.stop());
            setStream(null);
            streamRef.current = null;
          }
        }
      }, 100);

      // éŸ³é‡ç›£æ¸¬ - å®Œå…¨åƒè€ƒèª¿éŸ³å™¨
      startAudioLevelMonitoring(stream);

    } catch (error) {
      console.error('éŒ„éŸ³å¤±æ•—:', error);
      if (error.name === 'NotAllowedError') {
        setState(prev => ({ ...prev, error: 'è«‹å…è¨±éº¥å…‹é¢¨æ¬Šé™ä»¥é€²è¡Œèª¿éŸ³', phase: 'idle' }));
      } else {
        setState(prev => ({ ...prev, error: 'ç„¡æ³•å•Ÿå‹•éŒ„éŸ³åŠŸèƒ½', phase: 'idle' }));
      }
    }
  }, [startAudioLevelMonitoring]);

  // ä¿å­˜ startRecording å‡½æ•¸åˆ° refï¼Œä»¥ä¾¿åœ¨æ’­æ”¾å®Œæˆå›èª¿ä¸­ä½¿ç”¨
  startRecordingRef.current = startRecording;

  // åœæ­¢éŒ„éŸ³ - åƒè€ƒèª¿éŸ³å™¨çš„å¯¦ç¾
  const stopRecording = useCallback(() => {
    console.log('ğŸ›‘ åœæ­¢éŒ„éŸ³æµç¨‹é–‹å§‹');

    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
      recordingTimerRef.current = null;
    }

    if (audioLevelTimerRef.current) {
      clearInterval(audioLevelTimerRef.current);
      audioLevelTimerRef.current = null;
    }

    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      setStream(null);
      streamRef.current = null;
    }
  }, [uploadRecording]);

  // åˆå§‹åŒ– - ç™¼é€ AA è«‹æ±‚
  useEffect(() => {
    const initializeLesson = async () => {
      // å‰µå»ºä¸€å€‹æœ€å°çš„æœ‰æ•ˆWebMéŸ³æª” - åƒè€ƒèª¿éŸ³å™¨çš„åšæ³•
      const webmHeader = new Uint8Array([
        0x1a, 0x45, 0xdf, 0xa3, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x1f,
        0x42, 0x86, 0x81, 0x01, 0x42, 0xf7, 0x81, 0x01, 0x42, 0xf2, 0x81, 0x04,
        0x42, 0xf3, 0x81, 0x08, 0x42, 0x82, 0x84, 0x77, 0x65, 0x62, 0x6d
      ]);
      const dummyBlob = new Blob([webmHeader], { type: 'audio/webm' });

      console.log('ğŸµ åˆå§‹åŒ–å–®éŸ³æ•™å­¸...');
      await sendLessonRequest('AA', dummyBlob);
    };

    if (state.phase === 'intro' && !hasInitialized.current) {
      hasInitialized.current = true;
      initializeLesson();
    }
  }, [state.phase, sendLessonRequest]);

  // Debug: Track currentNote changes
  useEffect(() => {
    console.log('ğŸ” currentNote changed to:', state.currentNote);
  }, [state.currentNote]);

  // æ¸…ç†è³‡æº
  useEffect(() => {
    return () => {
      console.log('ğŸ§¹ æ¸…ç†çµ„ä»¶è³‡æº');

      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
        recordingTimerRef.current = null;
      }

      if (audioLevelTimerRef.current) {
        clearInterval(audioLevelTimerRef.current);
        audioLevelTimerRef.current = null;
      }

      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }

      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }

      if (instructionAudioRef.current) {
        instructionAudioRef.current.pause();
        instructionAudioRef.current.src = '';
      }
    };
  }, []);

  // æ¸²æŸ“é€²åº¦æŒ‡ç¤ºå™¨
  const renderProgress = () => {
    const progressPercentage = (state.answeredNotes.size / 7) * 100;

    return (
      <div className="lesson-progress">
        <div className="progress-header">
          <span>é€²åº¦: {state.answeredNotes.size} / 7</span>
        </div>
        <div className="progress-bar">
          <div
            className="progress-fill"
            style={{ width: `${progressPercentage}%` }}
          />
        </div>
        <div className="questions-status">
          {Array.from({ length: 7 }, (_, index) => {
            const questionNumber = index + 1;
            const answered = state.answeredNotes.size > index;
            const current = state.answeredNotes.size === index;

            return (
              <div
                key={questionNumber}
                className={`question-indicator ${answered ? 'answered' : ''} ${current ? 'current' : ''}`}
              >
                {questionNumber}
              </div>
            );
          })}
        </div>
      </div>
    );
  };

  // æ¸²æŸ“éŸ³é‡æ¢
  const renderVolumeBar = () => {
    if (state.phase !== 'recording') return null;

    return (
      <div className="volume-container">
        <div className="volume-label">éŸ³é‡</div>
        <div className="volume-bar">
          <div
            className="volume-fill"
            style={{ width: `${Math.min((state.audioLevel / 128) * 100, 100)}%` }}
          />
        </div>
      </div>
    );
  };

  // æ¸²æŸ“ä¸»è¦ç‹€æ…‹
  const renderMainStatus = () => {
    switch (state.phase) {
      case 'intro':
        return (
          <div className="status-display">
            <div className="note-name">æº–å‚™ä¸­...</div>
            <div className="status-text">æ­£åœ¨åˆå§‹åŒ–æ•™å­¸</div>
          </div>
        );

      case 'idle':
        return (
          <div className="status-display">
            <div className="status-label">è«‹å½ˆï¼š</div>
            <div className="note-name">{state.currentNote}</div>
            <div className="status-text">é»æ“Šä¸‹æ–¹æŒ‰éˆ•é–‹å§‹éŒ„éŸ³</div>
          </div>
        );

      case 'recording':
        return (
          <div className="status-display">
            <div className="note-name">{state.currentNote}</div>
            <div className="status-text">éŒ„éŸ³ä¸­... {Math.round(state.recordingTime * 10) / 10}s / {RECORD_SECONDS}s</div>
            {renderVolumeBar()}
          </div>
        );

      case 'uploading':
        return (
          <div className="status-display">
            <div className="note-name">{state.currentNote}</div>
            <div className="status-text">åˆ†æä¸­...</div>
          </div>
        );

      case 'playing':
        return (
          <div className="status-display">
            <div className="note-name">{state.currentNote}</div>
            <div className="status-text">æ’­æ”¾æŒ‡å°èªéŸ³ä¸­...</div>
          </div>
        );

      case 'done':
        return (
          <div className="status-display">
            <div className="note-name">ğŸ‰</div>
            <div className="status-text">æ•™å­¸å®Œæˆï¼</div>
            <div className="completion-message">3ç§’å¾Œè‡ªå‹•è¿”å›{navigationSource === 'picking-technique' ? 'æ’¥å¼¦æŠ€å·§é é¢' : 'åŸºç¤æ•™å­¸é é¢'}</div>
          </div>
        );

      default:
        return null;
    }
  };

  // æ¸²æŸ“æ§åˆ¶æŒ‰éˆ•
  const renderControls = () => {
    if (state.phase === 'done') {
      return null;
    }

    return (
      <div className="tuning-controls">
        <div className="status-indicator">
          {state.phase === 'idle' ? (
            <div className="status-message">
              ğŸ¤ èªéŸ³æŒ‡ç¤ºå®Œæˆå¾Œè‡ªå‹•éŒ„éŸ³
            </div>
          ) : state.phase === 'recording' ? (
            <div className="status-message">
              ğŸ¤ éŒ„éŸ³ä¸­... ({Math.round(state.recordingTime * 10) / 10}s/{RECORD_SECONDS}s)
            </div>
          ) : state.phase === 'uploading' ? (
            <div className="status-message">
              â³ åˆ†æä¸­...
            </div>
          ) : state.phase === 'playing' ? (
            <div className="status-message">
              ğŸ”Š æ’­æ”¾æŒ‡ç¤ºä¸­...
            </div>
          ) : state.phase === 'intro' ? (
            <div className="status-message">
              ğŸµ åˆå§‹åŒ–ä¸­...
            </div>
          ) : (
            <div className="status-message">
              â³ è«‹ç­‰å¾…...
            </div>
          )}
        </div>
      </div>
    );
  };

  return (
    <PhoneContainer>
      <div className="lesson-container">
        <div className="lesson-header">
          <div className="header-top">
            <button className="back-btn" onClick={() => onNavigate(navigationSource === 'picking-technique' ? 'picking-technique' : 'basic-lesson')}>
              â† è¿”å›
            </button>
          </div>
          <h1>å³æ‰‹æ’¥å¼¦ï½œå–®éŸ³æ•™å­¸</h1>
          <p>è·Ÿéš¨æŒ‡å°å®Œæˆ 7 å€‹éŸ³ç¬¦çš„ç·´ç¿’</p>
        </div>

        {renderProgress()}

        <div className="current-lesson">
          {renderMainStatus()}
        </div>

        {renderControls()}

        {state.error && (
          <div className="error-toast">
            <span>{state.error}</span>
            <button
              className="error-close"
              onClick={() => setState(prev => ({ ...prev, error: null }))}
            >
              âœ•
            </button>
          </div>
        )}
      </div>
    </PhoneContainer>
  );
};

export default SingleNoteLessonPage;