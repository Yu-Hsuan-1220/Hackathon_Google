import React, { useState, useEffect, useRef, useCallback } from 'react';
import PhoneContainer from './PhoneContainer';
import './ChordLessonPage.css';

// éŒ„éŸ³ç§’æ•¸å¸¸æ•¸
const RECORD_SECONDS = 4;

// å’Œå¼¦é †åºå®šç¾©
const CHORD_SEQUENCE = ['C', 'G', 'F']; // 3å€‹åŸºæœ¬å’Œå¼¦

// ç‹€æ…‹ç®¡ç†çš„åˆå§‹ç‹€æ…‹
const initialState = {
  phase: 'intro', // intro â†’ idle â†’ recording â†’ uploading â†’ playing â†’ done
  currentChord: '', // ç•¶å‰è¦ç·´ç¿’çš„å’Œå¼¦
  wholeChord: true, // true=æ•´å€‹å’Œå¼¦ä¸€èµ·ï¼Œfalse=é€å¼¦ç·´ç¿’
  currentString: null, // ç•¶å‰è¦ç·´çš„å¼¦è™Ÿ (1-6)
  completedChords: new Set(), // å·²å®Œæˆçš„å’Œå¼¦é›†åˆ
  error: null,
  recordingTime: 0,
  audioLevel: 0,
  isPlayingInstruction: false
};

const ChordLessonPage = ({ onNavigate }) => {
  const [state, setState] = useState(initialState);
  const [stream, setStream] = useState(null);
  const streamRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const recordingTimerRef = useRef(null);
  const currentChordRef = useRef(''); // è·Ÿè¸ªæœ€æ–°çš„å’Œå¼¦ç‹€æ…‹
  const currentStringRef = useRef(null); // è·Ÿè¸ªæœ€æ–°çš„å¼¦ç‹€æ…‹
  const wholeChordRef = useRef(true); // è·Ÿè¸ªæ˜¯å¦ç‚ºæ•´å’Œå¼¦æ¨¡å¼
  const audioLevelTimerRef = useRef(null);
  const analyserRef = useRef(null);
  const animationFrameRef = useRef(null);
  const audioContextRef = useRef(null);

  // å–å¾—ç”¨æˆ¶åª’é«”æµ
  const getUserMedia = useCallback(async () => {
    try {
      const mediaStream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          channelCount: 1,
          sampleRate: 24000,
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false
        } 
      });
      
      setStream(mediaStream);
      streamRef.current = mediaStream;

      // è¨­ç½®éŸ³é‡åˆ†æå™¨
      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
      analyserRef.current = audioContextRef.current.createAnalyser();
      const source = audioContextRef.current.createMediaStreamSource(mediaStream);
      source.connect(analyserRef.current);
      analyserRef.current.fftSize = 256;

      return mediaStream;
    } catch (error) {
      console.error('ç²å–éº¥å…‹é¢¨æ¬Šé™å¤±æ•—:', error);
      setState(prev => ({ ...prev, error: 'ç„¡æ³•å­˜å–éº¥å…‹é¢¨' }));
      throw error;
    }
  }, []);

  // é–‹å§‹éŒ„éŸ³
  const startRecording = useCallback(async () => {
    try {
      setState(prev => ({ ...prev, phase: 'recording', recordingTime: 0, error: null }));
      
      let currentStream = streamRef.current;
      if (!currentStream) {
        currentStream = await getUserMedia();
      }

      audioChunksRef.current = [];
      
      // å°è¯•ä½¿ç”¨æ›´å…¼å®¹çš„éŸ³é¢‘æ ¼å¼
      let mimeType = 'audio/wav';
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/webm';
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = 'audio/webm;codecs=opus';
        }
      }
      
      console.log('ä½¿ç”¨éŸ³é¢‘æ ¼å¼:', mimeType);
      
      mediaRecorderRef.current = new MediaRecorder(currentStream, {
        mimeType: mimeType
      });

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorderRef.current.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });
        uploadRecording(audioBlob);
      };

      mediaRecorderRef.current.start();

      // éŒ„éŸ³è¨ˆæ™‚å™¨
      recordingTimerRef.current = setInterval(() => {
        setState(prev => {
          const newTime = prev.recordingTime + 0.1;
          if (newTime >= RECORD_SECONDS) {
            clearInterval(recordingTimerRef.current);
            if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
              mediaRecorderRef.current.stop();
            }
            return { ...prev, recordingTime: RECORD_SECONDS };
          }
          return { ...prev, recordingTime: newTime };
        });
      }, 100);

      // éŸ³é‡æª¢æ¸¬
      startAudioLevelDetection();

    } catch (error) {
      console.error('é–‹å§‹éŒ„éŸ³å¤±æ•—:', error);
      setState(prev => ({ ...prev, error: 'éŒ„éŸ³å¤±æ•—', phase: 'idle' }));
    }
  }, [getUserMedia]);

  // éŸ³é‡æª¢æ¸¬
  const startAudioLevelDetection = useCallback(() => {
    if (!analyserRef.current) return;

    const bufferLength = analyserRef.current.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    const detectLevel = () => {
      if (analyserRef.current) {
        analyserRef.current.getByteFrequencyData(dataArray);
        const average = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;
        const normalizedLevel = Math.min(average / 128, 1);
        
        setState(prev => ({ ...prev, audioLevel: normalizedLevel }));
        
        if (audioLevelTimerRef.current) {
          animationFrameRef.current = requestAnimationFrame(detectLevel);
        }
      }
    };

    audioLevelTimerRef.current = true;
    detectLevel();
  }, []);

  // åœæ­¢éŸ³é‡æª¢æ¸¬
  const stopAudioLevelDetection = useCallback(() => {
    audioLevelTimerRef.current = false;
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }
    setState(prev => ({ ...prev, audioLevel: 0 }));
  }, []);

  // ä¸Šå‚³éŒ„éŸ³
  const uploadRecording = useCallback(async (audioBlob) => {
    try {
      setState(prev => ({ ...prev, phase: 'uploading' }));
      stopAudioLevelDetection();

      const formData = new FormData();
      const currentChord = currentChordRef.current || 'AA';
      const wholeChord = wholeChordRef.current;
      const currentString = currentStringRef.current;
      
      // åœ¨é€å¼¦æ¨¡å¼ä¸‹ï¼Œç¡®ä¿æœ‰å¼¦å·
      if (!wholeChord && !currentString) {
        console.error('é€å¼¦æ¨¡å¼ä¸‹ç¼ºå°‘å¼¦å·ï¼Œå–æ¶ˆä¸Šä¼ ');
        console.log('DEBUG: wholeChord =', wholeChord, 'currentString =', currentString);
        setState(prev => ({ 
          ...prev, 
          error: 'ç³»ç»Ÿæ­£åœ¨åˆ‡æ¢åˆ°é€å¼¦æ¨¡å¼ï¼Œè¯·ç¨åå†è¯•',
          phase: 'idle'
        }));
        return;
      }
      
      formData.append('target_chord', currentChord);
      formData.append('whole_chord', wholeChord ? 1 : 0);
      formData.append('string', currentString ? String(currentString) : '');
      formData.append('audio_file', audioBlob, 'audio.webm');

      console.log('ç•¶å‰ç‹€æ…‹ - currentChord ref:', currentChordRef.current);
      console.log('ç•¶å‰ç‹€æ…‹ - wholeChord ref:', wholeChordRef.current);
      console.log('ç•¶å‰ç‹€æ…‹ - currentString ref:', currentStringRef.current);
      console.log('ç™¼é€è«‹æ±‚:', {
        target_chord: currentChord,
        whole_chord: wholeChord ? 1 : 0,
        string: currentString ? String(currentString) : '',
        audioSize: audioBlob.size
      });

      const response = await fetch('http://127.0.0.1:8000/chord/chord-check', {
        method: 'POST',
        mode: 'cors',
        headers: { 'Accept': 'application/json' },
        body: formData
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();
      console.log('å¾Œç«¯å›æ‡‰:', data);

      await processChordResponse(data);

    } catch (error) {
      console.error('ä¸Šå‚³éŒ„éŸ³å¤±æ•—:', error);
      setState(prev => ({ 
        ...prev, 
        error: `ä¸Šå‚³å¤±æ•—: ${error.message}`,
        phase: 'idle'
      }));
    }
  }, [stopAudioLevelDetection]); // ç§»é™¤ç‹€æ…‹ä¾è³´ï¼Œç¢ºä¿ç¸½æ˜¯ä½¿ç”¨æœ€æ–°ç‹€æ…‹

  // è™•ç†å’Œå¼¦æª¢æ¸¬å›æ‡‰
  const processChordResponse = useCallback(async (response) => {
    try {
      console.log('è™•ç†å’Œå¼¦å›æ‡‰:', response);
      console.log('æ›´æ–°å‰çš„ currentChord:', currentChordRef.current);

      // æ›´æ–° ref
      console.log('DEBUG: response.details?.next_string =', response.details?.next_string);
      console.log('DEBUG: response.next_string =', response.next_string);
      console.log('DEBUG: æ›´æ–°å‰ currentStringRef.current =', currentStringRef.current);
      
      currentChordRef.current = response.target_chord;
      wholeChordRef.current = response.whole_chord === 1;
      currentStringRef.current = response.details?.next_string || response.next_string || null;
      
      console.log('DEBUG: æ›´æ–°å currentStringRef.current =', currentStringRef.current);
      
      // æ›´æ–°ç‹€æ…‹
      setState(prev => {
        console.log('ç‹€æ…‹æ›´æ–°: currentChord å¾', prev.currentChord, 'åˆ°', response.target_chord);
        console.log('ç‹€æ…‹æ›´æ–°: wholeChord å¾', prev.wholeChord, 'åˆ°', response.whole_chord === 1);
        console.log('ç‹€æ…‹æ›´æ–°: currentString å¾', prev.currentString, 'åˆ°', response.details?.next_string || response.next_string);
        return {
          ...prev,
          currentChord: response.target_chord,
          wholeChord: response.whole_chord === 1,
          currentString: response.details?.next_string || response.next_string || null  // ä¿®æ­£ï¼šå…ˆæ£€æŸ¥ detailsï¼Œå†æ£€æŸ¥æ ¹çº§åˆ«
        };
      });

      // æ’­æ”¾æŒ‡å°èªéŸ³
      if (response.audio) {
        // ä½¿ç”¨ Audio å‡½æ•¸ç›´æ¥å¾ frontend/public/audio/chord æ’­æ”¾
        let audioPath = response.audio;
        
        // å°‡å¾Œç«¯è¿”å›çš„è·¯å¾‘è½‰æ›ç‚ºå‰ç«¯å¯ç”¨çš„è·¯å¾‘
        if (audioPath.startsWith('audio/chord/')) {
          audioPath = `/${audioPath}`;
        } else if (audioPath.startsWith('frontend/public/')) {
          audioPath = audioPath.replace('frontend/public/', '/');
        } else if (!audioPath.startsWith('/')) {
          audioPath = `/${audioPath}`;
        }
        
        console.log('æ’­æ”¾å’Œå¼¦æŒ‡å°éŸ³æª”:', audioPath);
        const audio = new Audio(audioPath);
        
        // æ’­æ”¾éŸ³æª”
        setState(prev => ({ ...prev, phase: 'playing' }));
        try {
          await new Promise((resolve, reject) => {
            audio.onended = () => {
              console.log('å’Œå¼¦æŒ‡å°éŸ³æª”æ’­æ”¾å®Œæˆ');
              // ç¡®ä¿çŠ¶æ€æ›´æ–°åå†å…è®¸å½•éŸ³
              setTimeout(() => {
                setState(prev => ({ ...prev, phase: 'idle' }));
              }, 100); // ç­‰å¾… 100ms ç¡®ä¿çŠ¶æ€åŒæ­¥
              resolve();
            };
            audio.onerror = (error) => {
              console.error('å’Œå¼¦æŒ‡å°éŸ³æª”æ’­æ”¾å¤±æ•—:', error);
              setState(prev => ({ ...prev, phase: 'idle' }));
              reject(error);
            };
            audio.play().catch(reject);
          });
        } catch (audioError) {
          console.error('éŸ³æª”æ’­æ”¾éŒ¯èª¤:', audioError);
          setState(prev => ({ ...prev, phase: 'idle' }));
          // ä¸é˜»æ­¢æµç¨‹ç¹¼çºŒ
        }
      } else {
        // æ²’æœ‰éŸ³æª”æ™‚ç›´æ¥é€²å…¥ idle ç‹€æ…‹
        setState(prev => ({ ...prev, phase: 'idle' }));
      }

      // æª¢æŸ¥æ˜¯å¦å®Œæˆèª²ç¨‹
      if (response.finish_lesson) {
        console.log('ğŸ‰ å’Œå¼¦èª²ç¨‹å®Œæˆï¼');
        setState(prev => ({ ...prev, phase: 'done' }));
        setTimeout(() => {
          onNavigate('home');
        }, 3000);
        return;
      }

      // æª¢æŸ¥æ˜¯å¦å®Œæˆç•¶å‰å’Œå¼¦
      if (response.details?.is_correct) {
        console.log(`âœ… ${response.target_chord} å’Œå¼¦å®Œæˆ`);
        setState(prev => ({
          ...prev,
          completedChords: new Set([...prev.completedChords, response.target_chord])
        }));
      }

    } catch (error) {
      console.error('è™•ç†å›æ‡‰å¤±æ•—:', error);
      setState(prev => ({ 
        ...prev, 
        error: 'è™•ç†å›æ‡‰å¤±æ•—',
        phase: 'idle'
      }));
    }
  }, [onNavigate]);

  // åˆå§‹åŒ–
  const initializeLesson = useCallback(async () => {
    try {
      console.log('åˆå§‹åŒ–å’Œå¼¦èª²ç¨‹...');
      setState(prev => ({ ...prev, phase: 'intro' }));

      // ç™¼é€åˆå§‹åŒ–è«‹æ±‚ (target_chord = "AA")
      const formData = new FormData();
      formData.append('target_chord', 'AA');
      formData.append('whole_chord', 1);
      formData.append('string', '');
      
      // å‰µå»ºç©ºçš„éŸ³æª” Blob
      const emptyBlob = new Blob([], { type: 'audio/webm;codecs=opus' });
      formData.append('audio_file', emptyBlob, 'empty.webm');

      const response = await fetch('http://127.0.0.1:8000/chord/chord-check', {
        method: 'POST',
        mode: 'cors',
        headers: { 'Accept': 'application/json' },
        body: formData
      });

      if (!response.ok) {
        throw new Error(`åˆå§‹åŒ–å¤±æ•—: ${response.status}`);
      }

      const data = await response.json();
      console.log('åˆå§‹åŒ–å›æ‡‰:', data);

      await processChordResponse(data);

    } catch (error) {
      console.error('åˆå§‹åŒ–å¤±æ•—:', error);
      setState(prev => ({ 
        ...prev, 
        error: 'åˆå§‹åŒ–å¤±æ•—',
        phase: 'idle',
        currentChord: 'C' // é è¨­ç¬¬ä¸€å€‹å’Œå¼¦
      }));
    }
  }, [processChordResponse]);

  // çµ„ä»¶åˆå§‹åŒ–
  useEffect(() => {
    initializeLesson();
    getUserMedia();

    return () => {
      // æ¸…ç†è³‡æº
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
      }
      stopAudioLevelDetection();
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
    };
  }, [initializeLesson, getUserMedia, stopAudioLevelDetection]);

  // æ¸…é™¤éŒ¯èª¤
  const clearError = useCallback(() => {
    setState(prev => ({ ...prev, error: null }));
  }, []);

  // è¨ˆç®—é€²åº¦
  const getProgress = () => {
    return (state.completedChords.size / CHORD_SEQUENCE.length) * 100;
  };

  // å–å¾—ç•¶å‰æç¤ºæ–‡å­—
  const getCurrentInstruction = () => {
    if (state.phase === 'intro') {
      return 'æ­£åœ¨åˆå§‹åŒ–...';
    }
    if (state.phase === 'done') {
      return 'ğŸ‰ æ­å–œå®Œæˆå’Œå¼¦ç·´ç¿’ï¼';
    }
    if (!state.currentChord) {
      return 'æº–å‚™ä¸­...';
    }
    
    if (state.wholeChord) {
      return `è«‹å½ˆå¥ ${state.currentChord} å’Œå¼¦ (ä¸€æ¬¡åˆ·å®Œæ•´å’Œå¼¦)`;
    } else {
      return `è«‹ç·´ç¿’ ${state.currentChord} å’Œå¼¦ç¬¬ ${state.currentString} å¼¦`;
    }
  };

  return (
    <PhoneContainer>
      <div className="chord-lesson-container">
        {/* Header */}
        <div className="chord-lesson-header">
          <div className="header-top">
            <button 
              className="back-btn" 
              onClick={() => onNavigate('home')}
              disabled={state.phase === 'recording' || state.phase === 'uploading'}
            >
              â† è¿”å›
            </button>
          </div>
          <h1>åŸºæœ¬å’Œå¼¦ç·´ç¿’</h1>
          <p>å®Œæˆ 3 å€‹åŸºæœ¬å’Œå¼¦çš„ç·´ç¿’</p>
        </div>

        {/* é€²åº¦æŒ‡ç¤ºå™¨ */}
        <div className="chord-lesson-progress">
          <div className="progress-header">
            <span>é€²åº¦: {state.completedChords.size}/3</span>
          </div>
          <div className="progress-bar">
            <div 
              className="progress-fill" 
              style={{ width: `${getProgress()}%` }}
            ></div>
          </div>
          <div className="chords-status">
            {CHORD_SEQUENCE.map((chord, index) => (
              <div 
                key={chord}
                className={`chord-indicator ${
                  state.completedChords.has(chord) ? 'completed' : 
                  state.currentChord === chord ? 'current' : 'pending'
                }`}
              >
                {chord}
              </div>
            ))}
          </div>
        </div>

        {/* ä¸»è¦å…§å®¹å€åŸŸ */}
        <div className="chord-lesson-content">
          {/* ç•¶å‰å’Œå¼¦é¡¯ç¤º */}
          <div className="chord-display">
            <div className="chord-name">
              {state.currentChord || '---'}
            </div>
            <div className="instruction">
              {getCurrentInstruction()}
            </div>
          </div>

          {/* éŒ„éŸ³æ§åˆ¶å€åŸŸ */}
          <div className="recording-controls">
            {state.phase === 'idle' && (
              <button 
                className="record-btn" 
                onClick={startRecording}
              >
                ğŸ¤ é–‹å§‹éŒ„éŸ³
              </button>
            )}

            {state.phase === 'recording' && (
              <div className="recording-status">
                <div className="recording-indicator">
                  <div className="recording-dot"></div>
                  <span>éŒ„éŸ³ä¸­... {state.recordingTime.toFixed(1)}s</span>
                </div>
                <div className="audio-level-container">
                  <div 
                    className="audio-level-bar" 
                    style={{ width: `${state.audioLevel * 100}%` }}
                  ></div>
                </div>
              </div>
            )}

            {state.phase === 'uploading' && (
              <div className="uploading-status">
                <div className="loading-spinner"></div>
                <span>åˆ†æä¸­...</span>
              </div>
            )}

            {state.phase === 'playing' && (
              <div className="playing-status">
                <div className="playing-indicator">
                  <div className="playing-waves">
                    <span></span>
                    <span></span>
                    <span></span>
                  </div>
                  <span>æ’­æ”¾ä¸­...</span>
                </div>
              </div>
            )}

            {state.phase === 'done' && (
              <div className="completion-status">
                <div className="completion-icon">ğŸ‰</div>
                <div className="completion-text">
                  <h3>æ­å–œå®Œæˆï¼</h3>
                  <p>ä½ å·²ç¶“æŒæ¡äº†åŸºæœ¬å’Œå¼¦</p>
                  <p>3ç§’å¾Œè¿”å›é¦–é ...</p>
                </div>
              </div>
            )}
          </div>
        </div>

        {/* éŒ¯èª¤æç¤º */}
        {state.error && (
          <div className="error-toast" onClick={clearError}>
            <span>âš ï¸ {state.error}</span>
            <button className="close-btn">Ã—</button>
          </div>
        )}
      </div>
    </PhoneContainer>
  );
};

export default ChordLessonPage;